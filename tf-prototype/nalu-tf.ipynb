{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic testing of NALU\n",
    "\n",
    "See [here](https://arxiv.org/abs/1808.00508) for more info on the theory behind Neural Arithmetic Logic units.\n",
    "\n",
    "This notebook is loosely based on the implementation found [here](https://github.com/grananqvist/NALU-tf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nac import nac\n",
    "from nalu import nalu\n",
    "import GenData as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.01 # Per author's comment\n",
    "batch_size = 20\n",
    "\n",
    "X_data, Y_data = gd.gd_uniform(size=10000)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2]) \n",
    "Y_true = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "Y_pred = nalu(X, 1)\n",
    "\n",
    "loss = tf.losses.absolute_difference(Y_pred, Y_true) # testing with l1\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate) # Per author's comment\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nac_summary = tf.summary.scalar('nac', loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(epochs):    \n",
    "    i = 0\n",
    "    gts = 0\n",
    "        \n",
    "    while i < len(X_data):\n",
    "        xs, ys = X_data[i:i+batch_size], Y_data[i:i+batch_size]\n",
    "        _, ys_pred, l = sess.run([train_op, Y_pred, loss], feed_dict={X: xs, Y_true: ys})\n",
    "\n",
    "            # calculate number of correct predictions from batch\n",
    "        gts += np.sum(np.isclose(ys, ys_pred, atol=1e-4, rtol=1e-4)) \n",
    "        \n",
    "        # Log it for tensorBoard.\n",
    "        summary_str = nac_summary.eval(session=sess, feed_dict={X: xs, Y_true: ys})\n",
    "        step = ep *  len(X_data) + i\n",
    "        file_writer.add_summary(summary_str, step)\n",
    "        \n",
    "        i += batch_size\n",
    "        \n",
    "        \n",
    "    acc = gts/len(Y_data)\n",
    "    print('epoch {2}, loss: {0}, accuracy: {1}'.format(l, acc, ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saver = tf.train.Saver()\n",
    "#save_path = saver.save(sess, \"./model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "plot_data = pd.DataFrame(data={'index': [], 'error':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20, 5000):\n",
    "    Xtest, Ytest = gen_data_unif.generate_dataset(_min=i*10, _max=(i+1)*10-1, size=500)\n",
    "    _, _, l = sess.run([train_op, Y_pred, loss], feed_dict={X: Xtest, Y_true: Ytest})\n",
    "    plot_data = pd.concat([plot_data, pd.DataFrame({'index':[i*10], 'error':[l]})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data.plot(x='index', y='error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
